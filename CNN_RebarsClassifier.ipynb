{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoyDibs/Rebars-and-debris-Classiffication/blob/master/CNN_RebarsClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3y2hZgQYWWF",
        "outputId": "029a1f0e-2010-4ed7-db01-7f5da35d2edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  images2.zip\n",
            "   creating: images2/\n",
            "  inflating: images2/0.png           \n",
            "  inflating: images2/1.png           \n",
            "  inflating: images2/10.png          \n",
            "  inflating: images2/100.png         \n",
            "  inflating: images2/101.png         \n",
            "  inflating: images2/102.png         \n",
            "  inflating: images2/103.png         \n",
            "  inflating: images2/104.png         \n",
            "  inflating: images2/105.png         \n",
            "  inflating: images2/106.png         \n",
            "  inflating: images2/107.png         \n",
            "  inflating: images2/108.png         \n",
            "  inflating: images2/109.png         \n",
            "  inflating: images2/11.png          \n",
            "  inflating: images2/110.png         \n",
            "  inflating: images2/111.png         \n",
            "  inflating: images2/112.png         \n",
            "  inflating: images2/113.png         \n",
            "  inflating: images2/114.png         \n",
            "  inflating: images2/115.png         \n",
            "  inflating: images2/116.png         \n",
            "  inflating: images2/117.png         \n",
            "  inflating: images2/118.png         \n",
            "  inflating: images2/119.png         \n",
            "  inflating: images2/12.png          \n",
            "  inflating: images2/120.png         \n",
            "  inflating: images2/121.png         \n",
            "  inflating: images2/122.png         \n",
            "  inflating: images2/123.png         \n",
            "  inflating: images2/124.png         \n",
            "  inflating: images2/125.png         \n",
            "  inflating: images2/126.png         \n",
            "  inflating: images2/127.png         \n",
            "  inflating: images2/128.png         \n",
            "  inflating: images2/129.png         \n",
            "  inflating: images2/13.png          \n",
            "  inflating: images2/130.png         \n",
            "  inflating: images2/131.png         \n",
            "  inflating: images2/132.png         \n",
            "  inflating: images2/133.png         \n",
            "  inflating: images2/134.png         \n",
            "  inflating: images2/135.png         \n",
            "  inflating: images2/136.png         \n",
            "  inflating: images2/137.png         \n",
            "  inflating: images2/138.png         \n",
            "  inflating: images2/139.png         \n",
            "  inflating: images2/14.png          \n",
            "  inflating: images2/140.png         \n",
            "  inflating: images2/141.png         \n",
            "  inflating: images2/142.png         \n",
            "  inflating: images2/143.png         \n",
            "  inflating: images2/144.png         \n",
            "  inflating: images2/145.png         \n",
            "  inflating: images2/146.png         \n",
            "  inflating: images2/147.png         \n",
            "  inflating: images2/148.png         \n",
            "  inflating: images2/149.png         \n",
            "  inflating: images2/15.png          \n",
            "  inflating: images2/150.png         \n",
            "  inflating: images2/151.png         \n",
            "  inflating: images2/152.png         \n",
            "  inflating: images2/153.png         \n",
            "  inflating: images2/154.png         \n",
            "  inflating: images2/155.png         \n",
            "  inflating: images2/156.png         \n",
            "  inflating: images2/157.png         \n",
            "  inflating: images2/158.png         \n",
            "  inflating: images2/159.png         \n",
            "  inflating: images2/16.png          \n",
            "  inflating: images2/160.png         \n",
            "  inflating: images2/161.png         \n",
            "  inflating: images2/162.png         \n",
            "  inflating: images2/163.png         \n",
            "  inflating: images2/164.png         \n",
            "  inflating: images2/165.png         \n",
            "  inflating: images2/166.png         \n",
            "  inflating: images2/167.png         \n",
            "  inflating: images2/168.png         \n",
            "  inflating: images2/169.png         \n",
            "  inflating: images2/17.png          \n",
            "  inflating: images2/170.png         \n",
            "  inflating: images2/171.png         \n",
            "  inflating: images2/172.png         \n",
            "  inflating: images2/173.png         \n",
            "  inflating: images2/174.png         \n",
            "  inflating: images2/175.png         \n",
            "  inflating: images2/176.png         \n",
            "  inflating: images2/177.png         \n",
            "  inflating: images2/178.png         \n",
            "  inflating: images2/179.png         \n",
            "  inflating: images2/18.png          \n",
            "  inflating: images2/180.png         \n",
            "  inflating: images2/181.png         \n",
            "  inflating: images2/182.png         \n",
            "  inflating: images2/183.png         \n",
            "  inflating: images2/184.png         \n",
            "  inflating: images2/185.png         \n",
            "  inflating: images2/186.png         \n",
            "  inflating: images2/187.png         \n",
            "  inflating: images2/188.png         \n",
            "  inflating: images2/189.png         \n",
            "  inflating: images2/19.png          \n",
            "  inflating: images2/190.png         \n",
            "  inflating: images2/191.png         \n",
            "  inflating: images2/192.png         \n",
            "  inflating: images2/193.png         \n",
            "  inflating: images2/194.png         \n",
            "  inflating: images2/195.png         \n",
            "  inflating: images2/196.png         \n",
            "  inflating: images2/197.png         \n",
            "  inflating: images2/198.png         \n",
            "  inflating: images2/199.png         \n",
            "  inflating: images2/2.png           \n",
            "  inflating: images2/20.png          \n",
            "  inflating: images2/200.png         \n",
            "  inflating: images2/21.png          \n",
            "  inflating: images2/22.png          \n",
            "  inflating: images2/23.png          \n",
            "  inflating: images2/24.png          \n",
            "  inflating: images2/25.png          \n",
            "  inflating: images2/26.png          \n",
            "  inflating: images2/27.png          \n",
            "  inflating: images2/28.png          \n",
            "  inflating: images2/29.png          \n",
            "  inflating: images2/3.png           \n",
            "  inflating: images2/30.png          \n",
            "  inflating: images2/31.png          \n",
            "  inflating: images2/32.png          \n",
            "  inflating: images2/33.png          \n",
            "  inflating: images2/34.png          \n",
            "  inflating: images2/35.png          \n",
            "  inflating: images2/36.png          \n",
            "  inflating: images2/37.png          \n",
            "  inflating: images2/38.png          \n",
            "  inflating: images2/39.png          \n",
            "  inflating: images2/4.png           \n",
            "  inflating: images2/40.png          \n",
            "  inflating: images2/41.png          \n",
            "  inflating: images2/42.png          \n",
            "  inflating: images2/43.png          \n",
            "  inflating: images2/44.png          \n",
            "  inflating: images2/45.png          \n",
            "  inflating: images2/46.png          \n",
            "  inflating: images2/47.png          \n",
            "  inflating: images2/48.png          \n",
            "  inflating: images2/49.png          \n",
            "  inflating: images2/5.png           \n",
            "  inflating: images2/50.png          \n",
            "  inflating: images2/51.png          \n",
            "  inflating: images2/52.png          \n",
            "  inflating: images2/53.png          \n",
            "  inflating: images2/54.png          \n",
            "  inflating: images2/55.png          \n",
            "  inflating: images2/56.png          \n",
            "  inflating: images2/57.png          \n",
            "  inflating: images2/58.png          \n",
            "  inflating: images2/59.png          \n",
            "  inflating: images2/6.png           \n",
            "  inflating: images2/60.png          \n",
            "  inflating: images2/61.png          \n",
            "  inflating: images2/62.png          \n",
            "  inflating: images2/63.png          \n",
            "  inflating: images2/64.png          \n",
            "  inflating: images2/65.png          \n",
            "  inflating: images2/66.png          \n",
            "  inflating: images2/67.png          \n",
            "  inflating: images2/68.png          \n",
            "  inflating: images2/69.png          \n",
            "  inflating: images2/7.png           \n",
            "  inflating: images2/70.png          \n",
            "  inflating: images2/71.png          \n",
            "  inflating: images2/72.png          \n",
            "  inflating: images2/73.png          \n",
            "  inflating: images2/74.png          \n",
            "  inflating: images2/75.png          \n",
            "  inflating: images2/76.png          \n",
            "  inflating: images2/77.png          \n",
            "  inflating: images2/78.png          \n",
            "  inflating: images2/79.png          \n",
            "  inflating: images2/8.png           \n",
            "  inflating: images2/80.png          \n",
            "  inflating: images2/81.png          \n",
            "  inflating: images2/82.png          \n",
            "  inflating: images2/83.png          \n",
            "  inflating: images2/84.png          \n",
            "  inflating: images2/85.png          \n",
            "  inflating: images2/86.png          \n",
            "  inflating: images2/87.png          \n",
            "  inflating: images2/88.png          \n",
            "  inflating: images2/89.png          \n",
            "  inflating: images2/9.png           \n",
            "  inflating: images2/90.png          \n",
            "  inflating: images2/91.png          \n",
            "  inflating: images2/92.png          \n",
            "  inflating: images2/93.png          \n",
            "  inflating: images2/94.png          \n",
            "  inflating: images2/95.png          \n",
            "  inflating: images2/96.png          \n",
            "  inflating: images2/97.png          \n",
            "  inflating: images2/98.png          \n",
            "  inflating: images2/99.png          \n"
          ]
        }
      ],
      "source": [
        "# importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# for reading and augmenting images\n",
        "from skimage.io import imread\n",
        "from skimage.transform import rotate, resize\n",
        "\n",
        "# for splitting train-test set and evaluating the model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# PyTorch libraries \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam\n",
        "\n",
        "!unzip images2.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/rebars2.csv')\n",
        "\n",
        "# loading training images\n",
        "train_img = []\n",
        "train_img_values = []\n",
        "for img_name in train['image_names']:\n",
        "    image_path = '/content/images2/' + img_name\n",
        "    img = imread(image_path)\n",
        "    img = img/255\n",
        "    img = resize(img, output_shape=(3, 224, 224),\n",
        "                 mode='constant', anti_aliasing=True)\n",
        "    train_img.append(img)\n",
        "\n",
        "\n",
        "train_x = np.array(train_img)\n",
        "\n",
        "# defining the labels\n",
        "train_y = train['rebars_or_not'].values\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.2, random_state=13, stratify=train_y)\n",
        "print(\"Number of images (Before Image Augmentation) in Training set : \",train_x.shape[0],\"  Number of images in Testing set : \",test_x.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSm3PNbuYes4",
        "outputId": "b0956566-a72a-4852-e85a-1605afa6b837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images (Before Image Augmentation) in Training set :  160   Number of images in Testing set :  41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Augmentation\n",
        "final_train_x = []\n",
        "final_train_y = []\n",
        "\n",
        "#train_x.shape[0]\n",
        "for i in range(train_x.shape[0]):\n",
        "    final_train_x.append(train_x[i])\n",
        "    final_train_x.append(rotate(train_x[i], angle=45, mode = 'wrap'))\n",
        "    final_train_x.append(np.fliplr(train_x[i]))\n",
        "    for j in range(3):\n",
        "      final_train_y.append(train_y[i])\n",
        "\n",
        "train_x = np.array(final_train_x)\n",
        "train_y = np.array(final_train_y)\n",
        "print(\"Number of images (After Image Augmentation) in Training set : \",train_x.shape[0],\"  Number of images in Testing set : \",test_x.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYnlTuZT1L82",
        "outputId": "9d6e29fe-4944-4456-94b5-1c14842de4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images (After Image Augmentation) in Training set :  1194   Number of images in Testing set :  100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_x = train_x.numpy()\n",
        "# train_y = train_y.numpy()\n",
        "# test_x = test_x.numpy()\n",
        "# test_y = test_y.numpy()\n",
        "# converting training images and its labels into torch format\n",
        "train_x = train_x.reshape(train_x.shape[0], 3, 224, 224) #1956 is the number of training images\n",
        "train_x  = torch.from_numpy(train_x)\n",
        "train_x = train_x.float()\n",
        "train_y = train_y.astype(int)\n",
        "train_y = torch.from_numpy(train_y)\n",
        "\n",
        "\n",
        "# converting test images and its labels into torch format\n",
        "test_x = test_x.reshape(test_x.shape[0], 3, 224, 224) #164 is the number of test images\n",
        "test_x  = torch.from_numpy(test_x)\n",
        "test_x = test_x.float()\n",
        "test_y = test_y.astype(int)\n",
        "test_y = torch.from_numpy(test_y)"
      ],
      "metadata": {
        "id": "ubEaV5rn5jwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "class Net(Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.cnn_layers = Sequential(\n",
        "            Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            ReLU(inplace=True),\n",
        "            BatchNorm2d(32),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            Dropout(p=0.25),\n",
        "            Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            ReLU(inplace=True),\n",
        "            BatchNorm2d(64),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            Dropout(p=0.25),\n",
        "            Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            ReLU(inplace=True),\n",
        "            BatchNorm2d(128),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            Dropout(p=0.25),\n",
        "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            ReLU(inplace=True),\n",
        "            BatchNorm2d(128),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            Dropout(p=0.25),\n",
        "        )\n",
        "\n",
        "        self.linear_layers = Sequential(\n",
        "            Linear(128 * 14 * 14, 512),\n",
        "            ReLU(inplace=True),\n",
        "            Dropout(),\n",
        "            Linear(512, 256),\n",
        "            ReLU(inplace=True),\n",
        "            Dropout(),\n",
        "            Linear(256,10),\n",
        "            ReLU(inplace=True),\n",
        "            Dropout(),\n",
        "            Linear(10,2)\n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "l_C2E5BfAyiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "optimizer = Adam(model.parameters(), lr=0.000075)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()"
      ],
      "metadata": {
        "id": "FL_6OCT58YRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch size of the model\n",
        "batch_size = 32\n",
        "\n",
        "# number of epochs to train the model\n",
        "n_epochs = 50\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    permutation = torch.randperm(train_x.size()[0])\n",
        "    training_loss = []\n",
        "    for i in range(0,train_x.size()[0], batch_size):\n",
        "\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        batch_x, batch_y = train_x[indices], train_y[indices]\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs,batch_y)\n",
        "\n",
        "        training_loss.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step() \n",
        "        \n",
        "    training_loss = np.average(training_loss)\n",
        "    print('epoch: \\t', epoch, '\\t training loss: \\t', training_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-J92jjc8bFK",
        "outputId": "9ebc8b00-69d5-4e57-cac1-3ee290b0d439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 1 \t training loss: \t 0.49921850389555883\n",
            "epoch: \t 2 \t training loss: \t 0.39909473845833227\n",
            "epoch: \t 3 \t training loss: \t 0.36141975537726756\n",
            "epoch: \t 4 \t training loss: \t 0.33978884784798874\n",
            "epoch: \t 5 \t training loss: \t 0.3245070313936786\n",
            "epoch: \t 6 \t training loss: \t 0.3105532381879656\n",
            "epoch: \t 7 \t training loss: \t 0.3094852525544794\n",
            "epoch: \t 8 \t training loss: \t 0.29419052718501343\n",
            "epoch: \t 9 \t training loss: \t 0.2969778023268047\n",
            "epoch: \t 10 \t training loss: \t 0.30031209164544154\n",
            "epoch: \t 11 \t training loss: \t 0.29057781417903145\n",
            "epoch: \t 12 \t training loss: \t 0.288523184625726\n",
            "epoch: \t 13 \t training loss: \t 0.284906195966821\n",
            "epoch: \t 14 \t training loss: \t 0.2824834295009312\n",
            "epoch: \t 15 \t training loss: \t 0.27654242515563965\n",
            "epoch: \t 16 \t training loss: \t 0.2678015465406995\n",
            "epoch: \t 17 \t training loss: \t 0.2675497976965026\n",
            "epoch: \t 18 \t training loss: \t 0.275429762115604\n",
            "epoch: \t 19 \t training loss: \t 0.2682835818513444\n",
            "epoch: \t 20 \t training loss: \t 0.2705781346088962\n",
            "epoch: \t 21 \t training loss: \t 0.2640684113690728\n",
            "epoch: \t 22 \t training loss: \t 0.2659823212184404\n",
            "epoch: \t 23 \t training loss: \t 0.2543839804436031\n",
            "epoch: \t 24 \t training loss: \t 0.2450239262298534\n",
            "epoch: \t 25 \t training loss: \t 0.2439864866043392\n",
            "epoch: \t 26 \t training loss: \t 0.2451749338131202\n",
            "epoch: \t 27 \t training loss: \t 0.2270756842580771\n",
            "epoch: \t 28 \t training loss: \t 0.23410426766464584\n",
            "epoch: \t 29 \t training loss: \t 0.2357409290577236\n",
            "epoch: \t 30 \t training loss: \t 0.2228052020072937\n",
            "epoch: \t 31 \t training loss: \t 0.2267922341431442\n",
            "epoch: \t 32 \t training loss: \t 0.22770445303697334\n",
            "epoch: \t 33 \t training loss: \t 0.220933420093436\n",
            "epoch: \t 34 \t training loss: \t 0.19665444328596718\n",
            "epoch: \t 35 \t training loss: \t 0.1942137677810694\n",
            "epoch: \t 36 \t training loss: \t 0.19410772464777293\n",
            "epoch: \t 37 \t training loss: \t 0.1904988128103708\n",
            "epoch: \t 38 \t training loss: \t 0.17462233287331305\n",
            "epoch: \t 39 \t training loss: \t 0.1813294444429247\n",
            "epoch: \t 40 \t training loss: \t 0.1761803467708983\n",
            "epoch: \t 41 \t training loss: \t 0.17514897206504093\n",
            "epoch: \t 42 \t training loss: \t 0.15332314381866077\n",
            "epoch: \t 43 \t training loss: \t 0.15068503233947253\n",
            "epoch: \t 44 \t training loss: \t 0.16540019488648364\n",
            "epoch: \t 45 \t training loss: \t 0.1367338704631517\n",
            "epoch: \t 46 \t training loss: \t 0.1273532551468203\n",
            "epoch: \t 47 \t training loss: \t 0.13376678663649058\n",
            "epoch: \t 48 \t training loss: \t 0.11652554659859131\n",
            "epoch: \t 49 \t training loss: \t 0.12661375208316664\n",
            "epoch: \t 50 \t training loss: \t 0.12605194639610617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch size of the model\n",
        "batch_size = 64\n",
        "# prediction for training set\n",
        "prediction = []\n",
        "target = []\n",
        "permutation = torch.randperm(train_x.size()[0])\n",
        "for i in range(0,train_x.size()[0], batch_size):\n",
        "    indices = permutation[i:i+batch_size]\n",
        "    batch_x, batch_y = train_x[indices], train_y[indices]\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(batch_x.cuda())\n",
        "\n",
        "    softmax = torch.exp(output).cpu()\n",
        "    prob = list(softmax.numpy())\n",
        "    predictions = np.argmax(prob, axis=1)\n",
        "    prediction.append(predictions)\n",
        "    target.append(batch_y)\n",
        "    \n",
        "# training accuracy\n",
        "accuracy = []\n",
        "for i in range(len(prediction)):\n",
        "    accuracy.append(accuracy_score(target[i].cpu(),prediction[i]))\n",
        "    \n",
        "print('training accuracy: \\t', np.average(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGY_-wRh8d3r",
        "outputId": "911cee22-84ab-4e8f-816b-86ebb3cf33ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training accuracy: \t 0.9489739974937343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the performance on validation set\n",
        "torch.manual_seed(0)\n",
        "# batch size of the model\n",
        "batch_size = 64\n",
        "# prediction for test set\n",
        "prediction = []\n",
        "target = []\n",
        "permutation = torch.randperm(test_x.size()[0])\n",
        "for i in range(0,test_x.size()[0], batch_size):\n",
        "    indices = permutation[i:i+batch_size]\n",
        "    batch_x, batch_y = test_x[indices], test_y[indices]\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(batch_x.cuda())\n",
        "\n",
        "    softmax = torch.exp(output).cpu()\n",
        "    prob = list(softmax.numpy())\n",
        "    predictions = np.argmax(prob, axis=1)\n",
        "    prediction.append(predictions)\n",
        "    target.append(batch_y)\n",
        "    \n",
        "# Test accuracy\n",
        "accuracy = []\n",
        "for i in range(len(prediction)):\n",
        "    accuracy.append(accuracy_score(target[i].cpu(),prediction[i]))\n",
        "    \n",
        "print('Test accuracy: \\t', np.average(accuracy))\n",
        "torch.save(model, 'CNN-model.pth')\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEzSQSHXBAYJ",
        "outputId": "90f19d22-cadb-4c94-94a3-a9c901164fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: \t 0.8958333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('CNN-model.pth')\n",
        "image_path = '/content/2.png' #Specify the image path\n",
        "img = imread(image_path)\n",
        "img = img/255\n",
        "img = resize(img, output_shape=(3, 224, 224),\n",
        "               mode='constant', anti_aliasing=True)\n",
        "img = img.astype('float32')\n",
        "img = np.array(img)\n",
        "\n",
        "img = img.reshape(1, 3, 224, 224) \n",
        "img = torch.from_numpy(img)\n",
        "img = img.float()\n",
        "\n",
        "output = model(img.cuda())\n",
        "softmax = torch.exp(output).cpu()\n",
        "prob = list(softmax.detach().numpy())\n",
        "predictions = np.argmax(prob, axis=1)\n",
        "print(predictions)\n",
        "if predictions == 0:\n",
        "  print('Image contains debris')\n",
        "else:\n",
        "  print('Image contains rebars')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKdm162RBFxS",
        "outputId": "152ac540-458a-4341-aa99-26af1b298ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n",
            "Image contains rebars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0b52PZKLUFMT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}